V4.17 
Computationally efficient tracking of multiple targets by 
probabilistic data association using neural networks* 
DEBASIS SENGUPTA AND RONALD A. ILTIS 
Department of Electrical and Computer Engineering 
University of California, Santa Barbara 
Santa Barbara, CA 93106 
Abstract 
The joint probabilistic data association (JPDA) algorithm 
has been previously reported to be suitable for the problem of 
tracking multiple targets in the presence of clutter. Although it 
make few assumptions and can handle many targets, the com- 
plexity of this algorithm increases rapidly with the number of 
targets and returns. An approximation of the JPDA has been 
suggested in this paper. The proposed algorithm uses an analog 
computational network to solve the data association problem. 
The problem is viewed as that of optimizing a suitably chosen 
objective function. Simple neural network structures for the ap- 
proximate minimization of such functions have been proposed by 
other researchers. The analog network used here offers a signifi- 
cant degree of parallelism and thus can compute the association 
probabilities more rapidly. Computer simulations indicate the 
ability of the algorithm to track many targets simultaneously in 
the presence of moderate density clutter. 
1. Introduction 
The problem of tracking multiple targets in the presence of 
clutter has derived considerable attention in recent years. The 
probabilistic data association (PDA) approach reduces the com- 
plexity of more sophisticated algorithms by focusing on the few 
most likely hypotheses [Bar-Shalom 19781. This is done by form- 
ing a validation gate around the predicted position of each tar- 
get and selecting only the returns inside the gate for association 
with the target. The algorithm assigns a probability, called the 
association probability, to  every hypothesis associating a return 
to  a target. A weighted average of the state estimates under all 
the hypotheses associating different returns to a particular target 
serves as the PDA estimate of the state of that target. The associ- 
ation probabilities are used as weights. Assuming the true return 
from a given target to be a Gaussian random vector with mean 
and covariance given by the predicted state vector and covari- 
ance matrix, the likelihood function can be evaluated under every 
hypothesis associating different returns to  that target. The as- 
sociation probabilities are computed from these likelihoods. The 
simplest of the PDA methods computes the association probabil- 
ities taking one target a t  a time, regardless of how close the other 
targets may be. For this reason the ordinary PDA tracker per- 
forms poorly while tracking crossing targets or when the targets 
are close to each other. This difficulty is alleviated by the joint 
probabilistic data association (JPDA) algorithm which computes 
the association probabilities from the joint likelihood functions 
corresponding to the joint hypotheses associating all the returns 
* This work was sponsored in part by the SDIO/IST program 
managed by the Office of Naval Research under contract no. 
N00014-85-K-0551. 
to different permutations of targets and clutter points [Fortmann 
et a1 19831. However the increase of complexity in the computa- 
tion of the association probabilities may prove significant for a 
number of targets in moderate density clutter. There have been 
efforts to  approach the performance of the JPDA by imitating its 
properties via ad hoc association rules [Fitzgerald 19861. How- 
ever the effectiveness of these approximations in tracking many 
targets in the presence of clutter is not guaranteed. 
This paper suggests the use of an analog computational net- 
work for computing the association probabilities. The task of 
finding these probabilities is viewed as a constrained optimiza- 
tion problem. The constraints are obtained by a careful evalu- 
ation of the properties of the JPDA association rule. Some of 
these constraints are analogous to those of the classical “Trav- 
eling salesman problem” (TSP) and hence the neural network 
solution of this problem suggested by Hopfield and Tank [1985] 
is used as a reference. 
2. Problem description and the PDA solution 
sidered. 
T dynamic systems of the following familiar form are con- 
zt(k + 1) = F t ( k ) z t ( k )  + wt(k ) ,  t 5 T (1) 
where z is the plant or target state vector, F is a known matrix 
describing the dynamics of the target and w is a vector of zero- 
mean Gaussian noise uncorrelated to  any such noise vector a t  a 
different instant of time. The superscript t corresponds to the 
tth target and k is the index of time. The plant noise vectors 
w t ( k )  for different targets are assumed to be uncorrelated with 
each other at all instants of time k .  The measurement model is 
z ( k )  = H ( k ) z t ( k )  + u ( k )  (2) 
where z is the measurement vector, H is a known matrix and 
U is a zerc-mean Gaussian noise vector independent of wt. The 
vectors U at different time instants are assumed to be independent 
of each other. The covariance matrices Q t ( k )  and R(k)  of wt(k )  
and u(k), respectively, are known. The initial state of the target 
t ,  t = 1 , 2 , . . . , T  is assumed to  be Gaussian with known mean 
vector kt(O1O) and known covariance matrix Pt(O1O). 
The PDA approach considers only a subset of measurements 
which are validated by an appropriate gate. The Zth return zr(k) 
is validated for the tth target if its Mahalanobis distance from 
the predicted location kt(klk - 1) of the tth target is less than a 
threshold, i .e. ,  
r;(k)’ = [ q ( k ) - H ( k ) k t ( k l k  - l)]%’*(k)-’ 
. [ z l (k)  - H(k)?’(klk - l)] 5 7’ (3) 
where 
W y k )  = H ( k ) P t ( k / k  - l )H(k)’+  R(k)  (4) 
2152 
CH2561-9/88/0000-2152 $1.00 0 1988 IEEE 
Pt(klk - 1) is the predicted error covariance for the t th tar- 
get and the threshold 7 is selected to produce a predetermined 
probability of erroneous rejection of the correct return. It is as- 
sumed for simplicity that the true return is a Gaussian random 
vector with mean H(k)?t(klk - 1) and covariance Pt(klk - 1). 
A validation matrix may be formed by using (3) in the following 
way. 
1 
0 otherwise 
if the Zth return belongs to Gt(k)  
[W4ll,t = { (5) 
where G'(k) is the validation region of the t th target. n(k) has 
dimension m(k) x T where m(k) is the total number of validated 
returns a t  the kth instant and Z indexes the set of these returns. 
The PDA state estimate is given by a weighted combination 
of all the estimates under different hypotheses. 
m(k)  
et(klk) = Bf(k)&:(klk) (6) 
I=O 
where &f(klk) is the state estimate under the hypothesis that  the 
Zth validated return came from the t th target. The weight @(k) 
corresponds to the probability that the lth return came from the 
tth target. The overall covariance update is 
m(k) 
Pt(klk) = P,t(W,t(klk) (7) 
1=0 
where P:(klk) is the covariance matrix corresponding to &f(klk). 
The various PDA techniques differ only in the ways they 
compute the association probabilities aj(k) which must satisfy 
m(k1 
Bj(k) = 1, t =  1,2, . . . ,T 
l=O 
The ordinary PDA focuses only on the returns in one validation 
region at  a time. If the probability of detecting the correct re- 
turn is PD and the probability of validating a detected return is 
Pa then it can be shown that [Fortmann et aZ 19831 the PDA 
association probabilities are 
where 
otherwise 
001 
. I  
Computation of the JPDA association probabilities is more com- 
plicated. Define a feasible hypothesis of joint events x(n, k) as a 
permutation of targets and clutter points which allows at  most 
one target to be associated with a given return and at  most one 
return to be associated with a given target. It was shown by 
Fortmann et a1 [1983] that the JPDA association probabilities 
are 
t=l 
1 < r < T, 0 5 I <  m(k) (11) 
where j r  is the return to which the r th  target is associated under 
a given hypothesis and the sum is over all feasible hypotheses 
which allow the Zth return to be associated with the t th target. 
In the above equation pf is as described in (10) except for a minor 
difference in the case of p: which is given by X ( l  - PD). c is a 
normalizing constant. (11) reflects the fact that the JPDA uses 
the joint likelihoods of all the returns while (9) shows that the 
ordinary PDA effectively uses a normalized version of the simple 
likelihood functions as the association probabilities. 
It is useful to examine the properties of #(k) which are ex- 
clusive to the JPDA. I t  is unlikely that @(k) will be large if 
B[(k) for some r # t is also large. Furthermore, a close exami- 
nation of (11) reveals that @(k) is large if, in addition to pf(k) 
being large, there is a highly likely combination of the remain- 
ing targets { r  : 1 < r < T, r # t} and the remaining returns 
{j : 1 5. j < m(k), j # I } .  A highly likely combination is indi- 
cated by a large value of the product of the corresponding pf(k)s. 
This property of the JPDA association probabilities was not con- 
sidered in the following ad hoc formula for the /3:(k)s proposed 
by Fitzgerald [1986]. 
The additional term Et p;(k) in the denominator (compare (9)) 
is introduced in order to reduce the chances of #(k) and P[(k), 
r # t being large at  the same time. The arbitrary constant 
po is expected to improve the performance in the presence of 
clutter. Another PDA scheme, called the nearest neighbor PDA 
(NNPDA), picks the joint hypothesis which best explains the 
ordinary PDA association probabilities described by (9). The 
resulting matrix of B(k)s consists only of 1s and Os. The task of 
choosing the nearest hypothesis may require an exhaustive search 
over all feasible hypotheses. All of the above PDA techniques can 
track two targets satisfactorily. However their performance in 
tracking more targets in the presence of moderate density clutter 
may be inadequate. 
The complexity of the JPDA is overwhelming for relatively 
large T and m(k), and yet a computationally efficient substitute 
based on a careful understanding of its properties is lacking. The 
next section develops a method which is expected to serve as an 
effective alternative to the JPDA tracking scheme. 
3. The traveling salesman problem and the JPDA 
The traveling salesman problem (TSP) is a well-known con- 
strained multidimensional optimization problem. Given a set of 
n cities and the distance between each pair of them, the task is to 
design a closed tour for a traveling salesmhn. The length of the 
tour should be minimized subject to the constraints that no city 
should be excluded or visited twice. For an n-city TSP, there 
are n!/2n distinct valid tours out of which the shortest has to 
be chosen. Hopfield and Tank [1985] proposed a neural network 
solution to the TSP by using n2 interconnected neurons. They 
formulated the problem as that of minimizing an objective (or 
energy) function of the form 
over all V;. They also designed an analog circuit which approxi- 
mately minimizes the above energy function. T;, represents the 
strength of connection from the output of the j t h  neuron to the 
2153 
input of the i th neuron while 1, represents the externally supplied 
input current to the i th neuron. The evolution of the circuit is 
described by the differential equation 
where s is the index of time, so is a time constant and U, is the 
input to the i th neuron. The output V, of the neuron is related 
to its input by a monotonically nondecreasing function g with 
domain (-00, CO) and range [0,1]. Although the circuit operates 
over the N-dimensional hypercube defined by 0 5 V, 5 1, the 
minima of (13) occur only at  the corners of the hypercube, pro- 
vided the connections are symmetric (T,J = T3,) .  In the case of 
TSP a propel: choice of a few design parameters causes the net- 
work to converge to a stable state or minimum which corresponds 
to one of the best few solutions. 
The problem of finding the association probabilities ,B:(k) 
from the likelihoods p : ( k )  described in the previous section has 
features similar to the TSP. If the output voltages of an (m(k)  + 
1) x T array of neurons are defined to be the association proba- 
bilities, then the columns would represent targets and the rows 
would indicate returns. The zeroth row would correspond to no 
return from a given target. The constraints of the data associ- 
ation problem (DAP) are as follows. Each column sum of the 
voltages must be unity so that (8) is satisfied. At most one large 
entry may be favored in every row and column in accordance with 
the assumptions that no two returns can come from the same tar- 
get and no return can come from two targets. @(k) should be 
large if p:(k)  is large and there is a combination of the remaining 
targets and returns which result in a large product of the cor- 
responding likelihoods. All these requirements are accomplished 
by minimizing the energy function 
where pf is a normalized version of the p:(k)s ,  
pf. is roughly the PDA association probability for the lth return 
and t th target (compare (9)). The ,Bi(k)s are obtained as the 
output 1 = O,l , .  . . , m(k),  t = 1 , 2 , - .  . ,T.  The index k is 
dropped for convenience. The first term achieves its minimum 
value of 0 when there is at most one large entry in each row. 
Similarly the second term inhibits more than one return to be 
strongly associated with a given target. The third term biases the 
final solution towards a normalized set of numbers. The fourth 
term favors associations which have a high likelihood and the fifth 
term favors a highly likely combination of the remaining targets 
and returns. Minimizing (15) can be shown to be equivalent to 
minimizing the energy function 
where 
and 
I; = C + (D + E)pf + E(T - 1 - C p I )  (19) 
Here 6,j is the usual Kronecker delta function. Equation (17) 
is equivalent to (13) except that each neuron is identified by a 
superscript as well as a'subscript. I t  may be observed that the 
strengths of connection T:; given by (18) do not depend on p : .  
Thus a new network need not be designed every time a new set of 
likelihood functions are available. Instead, the input currents 1; 
as described by (19) can be easily controlled by these functions. 
The equations of motion for this circuit are 
r 
Kt = g ( 4  (20a) 
- [D + E(T - l)]qt + (D + E)pt 
The coefficients A, B ,  C, D and E can be adjusted to control 
the emphasis on different constraints and properties. A large 
value of D will produce close to pf which are approximately 
the ordinary PDA association probabilities. A larger emphasis 
on A, B and C will produce the nearest neighbor solution (as in 
the TSP). This special case offers an attractive method of deter- 
mining the nearest hypothesis without explicitly examining all 
the hypotheses. Finally, a balanced combination of all five terms 
will lead to the most complete emulation of all the properties of 
the JPDA. A larger number of targets will only require a larger 
array of interconnected neurons instead of an increased load on 
any sequential software to compute the association probabilities. 
Figure 1 shows the block diagram of a tracker which uses the p r e  
posed analog network to compute the association probabilities. 
4. Simulation of performance 
The performance of the neural network PDA (NPDA) was 
simulated along with those of the Fitzgerald's simplified PDA 
(SPDA) and JPDA. Four targets were chosen with nearly con- 
stant velocities in a two dimensional plane. The discretized state 
equation for each target is given by (1) where 
2(k) = (z i: y '  y)' (21) 
(22) 
1 A O O  
P ( k ) =  (: ; ; :) V t ,  V k  
0 0 0 1  
using Cartesian coordinates in two dimensions. The quantities 
in the right hand side of (21) indicate the position and velocity 
a t  time k and target t .  The sampling interval (A) was assumed 
to be 0.5 second. The plant noise wt(k )  is assumed to be of the 
form [Fortmann 19831 
2154 
where (wL(k) wi(k))‘  is a vector of independent Gaussian ve- 
locity noises with associated variances (~:(k))~ = ( ~ i ( k ) ) ~  =
0.0009 km’s-’ V t ,  V k which correspond to a standard devia- 
tion of a t  least .04 times the mean velocity. These uncertainties 
allow for small changes of the target velocity. It was assumed 
that only position measurements are available so that 
1 0 0 0  
H ( k ) = ( o  0 1 0) 
for all k. The measurement noise covariance matrix is 
R(k) = diag(.0225, .09) 
assuming all the measurement noise to  be uncorrelated. The 
probability of validation Pc and the probability of detection Po 
were both assumed to  be 0.95. The corresponding threshold of 
the Mahalanobis distance, as obtained from the table of xi dis- 
tribution is 7 = m. This determines the size of the validation 
gate. A uniform clutter density’ of about 0.05 km-2 was chosen. 
This produced on the average 0.35 clutter point per validation 
gate. 
Equations (20a) and (20b) represent the evolution of the 
states of the analog circuit for the neural network solution of the 
DAP. The function g(u:) in (20a) was defined to be [Hopfield and 
Tank 19851 
Y t  = g(u;) = 1 (1 + tanh 2) 
2 (23) 
In order to avoid bias to any particular set of stable states, the 
initial states were chosen to  be such that they approximately 
produce cE_bk) Yt  = 1 V t initially. It is known [Hopfield and 
Tank 19851 that the addition of a random noise to the initial 
values enhances convergence. Accordingly the initial states were 
chosen to be 
where Suf is a random variable having uniform distribution over 
[-O.lu,, O.lu,]. The constant U,, was chosen to  be 0.02 to pro- 
duce a moderate rate of convergence. The differential equation 
(20b) was approximated by a difference equation with stepsize 
0.0005 s. so was selected to be 1 s. An experimentally deter- 
mined limit of 100 iterations was imposed on the recursive dif- 
ference equation. The 100th iterates xt(l0O), 15 m(k), t 5 T 
are expected to  be close to the steady state solutions of (20b). 
These values were normalized for each t to  ensure strict compli- 
ance with the constraint (8). The constants A, B, C, D and E 
were also chosen experimentally to produce a stable operating 
point. The values A = 1, B = 40, C = 1000, D = 30 and E = 5 
appeared to be suitable for two to four targets. 
Figure 2 shows the ability of the NPDA and the failure of the 
SPDA to track four targets in the presence of moderate density 
clutter. The SPDA association probabilities were computed from 
(12) with po = 0. No non-zero value of po appeared to improve 
its performance. The performance of the NPDA is equivalent to 
that of the JPDA in terms of rms position and velocity errors 
[Sengupta and Iltis 19871. 
5. Conclusion 
Computation of the association probabilities by an analog 
network appears to be a viable alternative to the JPDA. I t  out- 
performs the SPDA by accurately emulating all the properties 
of the JPDA. The coefficients of the function E D A ~  have to  be 
chosen suitably for a given number of targets and returns. Com- 
puter simulations indicate that a suitable operating point may 
be obtained for a range of complexity of the problem. The ana- 
log network is structurally simple and there is a high degree of 
parallelism inherent in it. A DAP of higher complexity will only 
require a larger array of neurons instead of increased burden on a 
sequential algorithm such as the JPDA. In spite of the necessity 
of D/A and A/D conversions, these attractive features may ren- 
der the NPDA useful for tracking a reasonable number of targets 
in the presence of moderate density clutter. 
References 
1. Y. Bar-Shalom, ‘(Tracking methods in a multitarget environ- 
ment,” Survey paper, IEEE Transactions on Automatic Control, 
2. R.J. Fitzgerald, “Development of practical PDA logic for mul- 
titarget tracking by microprocessor,” Proc. American Controls 
Conference, Seattle, WA, 1986, pp. 889-898. 
3. T.E. Fortmann, Y. Bar-Shalom and M. Scheffe, “Multitarget 
tracking using joint probabilistic data association,” IEEE Journal 
of Oceanic Eng., July 1983. 
4. J.J. Hopfield and D.W. Tank, ““Neural” Computation of de- 
cisions in optimizing problems,” Biological Cybernetics, Vol. 52, 
5 .  D. Sengupta and R.A. Iltis, ‘(Computationally efficient track- 
ing of multiple targets by probabilistic data association using 
neural networks,” Submitted to  IEEE Trans. on Aerospace and 
Electronic Systems, 1987. 
Vol. AC-23, NO. 4, Aug. 1978, pp. 618-626. 
1985, pp. 141-152. 
? 
Figure 1: Schematic diagram of NPDA tracker 
NPDA estimate1 
i r I - - ~ ~ - - -  SPDA estimate 
t rue  track 
t - - - .  - L  --i 
I 
-10 /
-5 0 5 10 15 
Figure 2: Tracking four targets by NPDA and SPDA 
