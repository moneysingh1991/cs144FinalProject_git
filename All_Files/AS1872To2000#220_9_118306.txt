S*dIUCHILD: A FAULT T O L P  ;’Tm 
WXJRAL “.JET’!OFK 
S l i z a b e t h  Kidwell 
ATBT Eel1 Labora tor ies  
Room 54-401 
2000 Narrenvi l le  Rea? 
Uapervi l le ,  IL 69566 
Abstract  
Bra inchi ld  i s  a neura l  network designed 
t o  br idge t h e  gap between currer l t  neura l  
models and t h e  brain.  It nodels  t h e  phys ica l  
o rganiza t ion  of  neurons by using both feed- 
forward and l a t e r a l  connections. It a l s o  has 
a high depree of f a u l t  t o l e r a n c e  i n  keeping 
with neura l  connections. A s e r i e s  of t e s t s  
were run on both Bra inchi ld  and a Hopfield 
model network t o  compare f a u l t  to le rance .  
Both hard and s o f t  f a u l t s  were used, a s  wel l  
as combinations o f  t h e  two. Bra inchi ld  proved 
t o  be t h e  more f a u l t  t o l e r a n t  of t h e  two. 
m R A L  ASSOCIATIVE MEMORIES USING CASCADE & RING ARCHITECTURES 
H o n  hung KIM and Chi Kin LEE 
Departmnt of E l e c t r i c a l  E n g i n e e r i n g  
U n i v e r s i t y  of Windsor 
Windsor, Ontario 
Canada NQB 3 P 4  
Abstract 
Three 
associative 
vectors, are 
methods to store temporal 
patterns, which are ordered 
presented. The first one is to 
use a single Bidirectional Associative 
Memories ( B A N ) ,  the second one is to use a 
Cascade Bidirectional Associative Memories 
(CBAM) and the third one is to use a Ring 
Unidirectional Associative Memories (RUAM). 
Their performances are compared by 
simulations which use words of four letters 
as the temporal associative data. These 
words can be recalled after one letter is 
input. Finally, the application o f  the RUAM 
to store autoassociative data is also 
discussed. 
ERROR CORRECTING NETWORK 
Jason M. Kinser 
Teledyne Brown Engineering 
Cummings Research Park 
Mail Stop 60 
Huntsville, AL 35807 
and 
University of Alabama in Huntsville 
Department of Physics 
Huntsville, AL 35899 
H. John Caulfield 
University of Alabama in Huntsville 
Center for Applied Optics 
Huntsville, AL 35899 
Abstract 
For many applications a simple neural network model 
with a high storage capacity would be sufficient. 
There have been networks proposed that are easy to 
implement, but have a low storage capacity. There are 
other networks that have high capacities, but are more 
tedious to implement. We propose a network that uses 
the simplest learning rules but exhibit a high storage 
capacity. This increase in storage capacity is 
achieved by introducing error correction on the output 
of traditional low capacity networks. Experimental 
error corrected recall indicated the Error Correcting 
Network had the ability to recall very nearly all of 
the available information produced by a simple 
Hopfield-type network long after the Hopfield-type net- 
work had failed to recall any association by itself. 
RECALL IN SATURATED ASSOCIATIVE NEURAL NETWORKS 
by 
Oscar Martlner and Cralg Harston 
Computer Appllcatlons Servlce 
6207 Forest TralI 
Slgnal Mountaln. Tn. 37377 
Abstract 
An assoc i at i ve neura i 
network was enhanced to provide 
both primary and secondary 
associative relationships on 
recall. input patterns, which 
were conceptually related, 
established extra relationships 
in the modified associative 
network. Not only did this 
network recall the original 
associated pattern when 
presented with a glven input, 
but it could identify the 
conceptually related input 
patterns. The output was 
separated into two groups. The 
primary output was the expected 
pattern associated with the 
input during training. The 
secondary output consisted o f  
the patterns associated with 
other inputs. This secondary 
information was limited to 
output patterns which were 
conceptually related to the 
training input. 
11-570 
